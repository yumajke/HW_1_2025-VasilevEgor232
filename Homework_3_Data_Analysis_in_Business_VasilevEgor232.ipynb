{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "import lightgbm as lgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "mRD4Es8IWAFt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REL_CLIP = 0.3\n",
        "ENSEMBLE_W_REL = 0.55\n",
        "ENSEMBLE_W_LOG = 0.45\n",
        "MAX_PRED_BY_PROD_Q = 0.999\n",
        "SMOOTH_ALPHA = 0.35\n",
        "RANDOM_STATE = 42"
      ],
      "metadata": {
        "id": "G-U8OzgGiVa3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "sample = pd.read_csv('sample_submission.csv')"
      ],
      "metadata": {
        "id": "Re0EibFXiXbP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Unnamed: 0' in train.columns:\n",
        "    train = train.rename(columns={'Unnamed: 0': 'id'})\n",
        "\n",
        "train = train[train['store_location_rk'] != 309].reset_index(drop=True)\n",
        "train['period_start_dt'] = pd.to_datetime(train['period_start_dt'], dayfirst=False, errors='coerce')\n",
        "test['period_start_dt'] = pd.to_datetime(test['period_start_dt'], dayfirst=True, errors='coerce')\n",
        "\n",
        "for df in [train, test]:\n",
        "    df['series_id'] = df['product_rk'].astype(str) + '_' + df['store_location_rk'].astype(str)\n",
        "\n",
        "promo_mode = train['PROMO1_FLAG'].mode().iloc[0] if 'PROMO1_FLAG' in train.columns else 0\n",
        "train['PROMO1_FLAG'] = train.get('PROMO1_FLAG', promo_mode).fillna(promo_mode)\n",
        "if 'PROMO1_FLAG' in test.columns:\n",
        "    test['PROMO1_FLAG'] = test['PROMO1_FLAG'].fillna(promo_mode)\n",
        "else:\n",
        "    test['PROMO1_FLAG'] = promo_mode\n",
        "\n",
        "for col in ['PRICE_REGULAR','PRICE_AFTER_DISC','AUTORIZATION_FLAG','PROMO2_FLAG','NUM_CONSULTANT']:\n",
        "    if col in train.columns:\n",
        "        train[col] = train.groupby(['product_rk','store_location_rk'])[col].transform(lambda s: s.ffill().bfill())\n",
        "        prod_med = train.groupby('product_rk')[col].transform('median')\n",
        "        train[col] = train[col].fillna(prod_med)\n",
        "        prod_med_map = train.groupby('product_rk')[col].median().to_dict()\n",
        "        test[col] = test['product_rk'].map(prod_med_map).fillna(0.0).values if 'product_rk' in test.columns else 0.0\n",
        "\n",
        "test = sample[['id']].merge(test, on='id', how='left')\n",
        "test['series_id'] = test['product_rk'].astype(str) + '_' + test['store_location_rk'].astype(str)"
      ],
      "metadata": {
        "id": "8pdTu6n-iaIq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_cols = ['product_rk','store_location_rk','period_start_dt']\n",
        "test_new = test.merge(train[key_cols].drop_duplicates().assign(_in_train=1), on=key_cols, how='left')\n",
        "test_new = test_new[test_new['_in_train'].isna()].drop(columns=['_in_train'])\n",
        "\n",
        "df = pd.concat([train, test_new], sort=False).reset_index(drop=True)\n",
        "df = df.sort_values(['series_id','period_start_dt']).reset_index(drop=True)\n",
        "\n",
        "df['week'] = df['period_start_dt'].dt.isocalendar().week.astype('Int64')\n",
        "df['month'] = df['period_start_dt'].dt.month.astype('Int64')\n",
        "df['weekday'] = df['period_start_dt'].dt.weekday.astype('Int64')\n",
        "df['year'] = df['period_start_dt'].dt.year.astype('Int64')\n",
        "\n",
        "df['demand'] = df['demand'].astype(float)\n",
        "df['demand_log'] = np.log1p(df['demand'])\n",
        "df['demand_relative'] = df.groupby('series_id')['demand'].pct_change().replace([np.inf,-np.inf], 0).fillna(0)"
      ],
      "metadata": {
        "id": "uUkUkTs1ic2c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lags = [1,2,3,4,8,12,52]\n",
        "for lag in lags:\n",
        "    df[f'd_lag_{lag}'] = df.groupby('series_id')['demand'].shift(lag)\n",
        "    df[f'log_lag_{lag}'] = df.groupby('series_id')['demand_log'].shift(lag)\n",
        "    df[f'rel_lag_{lag}'] = df.groupby('series_id')['demand_relative'].shift(lag)\n",
        "\n",
        "for w in [4,8,12]:\n",
        "    df[f'd_roll_mean_{w}'] = df.groupby('series_id')['demand'].shift(1).rolling(w, min_periods=1).mean()\n",
        "    df[f'd_roll_median_{w}'] = df.groupby('series_id')['demand'].shift(1).rolling(w, min_periods=1).median()\n",
        "    df[f'rel_roll_mean_{w}'] = df.groupby('series_id')['demand_relative'].shift(1).rolling(w, min_periods=1).mean()\n",
        "    df[f'rel_roll_std_{w}'] = df.groupby('series_id')['demand_relative'].shift(1).rolling(w, min_periods=1).std()\n",
        "\n",
        "if 'PRICE_REGULAR' in df.columns and 'PRICE_AFTER_DISC' in df.columns:\n",
        "    df['price_ratio'] = df['PRICE_AFTER_DISC'] / (df['PRICE_REGULAR'].replace(0, np.nan))\n",
        "    df['price_ratio'] = df['price_ratio'].replace([np.inf,-np.inf],1.0).fillna(1.0)\n",
        "    for lag in [1,2,4]:\n",
        "        df[f'price_ratio_lag_{lag}'] = df.groupby('series_id')['price_ratio'].shift(lag)\n",
        "else:\n",
        "    df['price_ratio'] = 1.0"
      ],
      "metadata": {
        "id": "JXDAYGiCifOt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'PROMO1_FLAG' in df.columns:\n",
        "    df['promo_prev_mean_4'] = df.groupby('series_id')['PROMO1_FLAG'].shift(1).rolling(4,min_periods=1).mean()\n",
        "\n",
        "series_stats = train.groupby('series_id')['demand'].agg(['median','mean','count','std']).rename(columns={'median':'series_median','mean':'series_mean','count':'series_count','std':'series_std'})\n",
        "df = df.merge(series_stats, left_on='series_id', right_index=True, how='left')\n",
        "\n",
        "prod_stats = train.groupby('product_rk')['demand'].agg(['median','mean','std']).rename(columns={'median':'prod_median','mean':'prod_mean','std':'prod_std'})\n",
        "df = df.merge(prod_stats, left_on='product_rk', right_index=True, how='left')\n",
        "\n",
        "feature_cols = [\n",
        "    'month','weekday','week','PRICE_REGULAR','PRICE_AFTER_DISC','price_ratio','promo_prev_mean_4',\n",
        "] + [f'd_lag_{l}' for l in lags] + [f'log_lag_{l}' for l in lags] + [f'rel_lag_{l}' for l in lags] + \\\n",
        "[f'd_roll_mean_{w}' for w in [4,8,12]] + [f'd_roll_median_{w}' for w in [4,8,12]] + [f'rel_roll_mean_{w}' for w in [4,8,12]]\n",
        "\n",
        "for c in feature_cols:\n",
        "    if c in df.columns:\n",
        "        df[c] = df.groupby('series_id')[c].transform(lambda s: s.fillna(method='ffill').fillna(method='bfill'))\n",
        "        df[c] = df[c].fillna(df['prod_median'])\n",
        "        df[c] = df[c].fillna(df['series_median'])\n",
        "        df[c] = df[c].fillna(0.0)\n",
        "\n",
        "train_proc = df[df['demand'].notna()].copy()\n",
        "test_proc = df[df['demand'].isna()].copy()\n",
        "\n",
        "print(f\"Processed: train rows {len(train_proc)}, test rows {len(test_proc)}\")\n",
        "\n",
        "rel_features = ['PRICE_REGULAR','PRICE_AFTER_DISC','price_ratio','promo_prev_mean_4',\n",
        "    'series_median','series_mean','prod_median','prod_mean'] + \\\n",
        "    [f'rel_lag_{l}' for l in lags] + [f'rel_roll_mean_{w}' for w in [4,8,12]] + ['month','weekday']\n",
        "\n",
        "log_features = ['PRICE_REGULAR','PRICE_AFTER_DISC','price_ratio','promo_prev_mean_4',\n",
        "    'series_median','series_mean','prod_median','prod_mean'] + \\\n",
        "    [f'log_lag_{l}' for l in lags] + [f'd_roll_mean_{w}' for w in [4,8,12]] + ['month','weekday']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOwD8B0viji-",
        "outputId": "eaf1c3e0-c0f5-4543-e3a3-2ea602ed504b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: train rows 34129, test rows 1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_rel = train_proc[rel_features].fillna(0)\n",
        "y_rel = train_proc['demand_relative'].fillna(0)\n",
        "\n",
        "X_log = train_proc[log_features].fillna(0)\n",
        "y_log = train_proc['demand_log'].fillna(0)\n",
        "\n",
        "m_rel = HistGradientBoostingRegressor(max_iter=800, learning_rate=0.08, max_depth=10, min_samples_leaf=20, random_state=RANDOM_STATE)\n",
        "m_rel.fit(X_rel, y_rel)\n",
        "\n",
        "lgb_train = lgb.Dataset(X_log, label=y_log)\n",
        "lgb_params = {\n",
        "    'objective':'regression','metric':'l2','learning_rate':0.05,'num_leaves':128,\n",
        "    'min_data_in_leaf':20,'feature_fraction':0.8,'bagging_fraction':0.8,'bagging_freq':5,\n",
        "    'verbosity':-1,'seed':RANDOM_STATE\n",
        "}\n",
        "m_log = lgb.train(lgb_params, lgb_train, num_boost_round=3000, valid_sets=[lgb_train], callbacks=[lgb.log_evaluation(period=500), lgb.early_stopping(stopping_rounds=200)])\n",
        "\n",
        "last_values = train_proc.groupby('series_id')['demand'].last()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ehfEr8mil8Z",
        "outputId": "5d016136-7580-4dc6-a27f-a93ad4f5764f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[500]\ttraining's l2: 0.162435\n",
            "[1000]\ttraining's l2: 0.0770931\n",
            "[1500]\ttraining's l2: 0.0393143\n",
            "[2000]\ttraining's l2: 0.0207897\n",
            "[2500]\ttraining's l2: 0.0114401\n",
            "[3000]\ttraining's l2: 0.00645121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_baseline_value(row):\n",
        "    s = row['series_id']\n",
        "    if 'd_lag_52' in row.index and not pd.isna(row['d_lag_52']):\n",
        "        return row['d_lag_52']\n",
        "    if s in last_values.index:\n",
        "        return last_values.loc[s]\n",
        "    if not pd.isna(row.get('prod_median', np.nan)):\n",
        "        return row['prod_median']\n",
        "    return train_proc['demand'].median()\n",
        "\n",
        "X_rel_test = test_proc[rel_features].fillna(0)\n",
        "X_log_test = test_proc[log_features].fillna(0)\n",
        "\n",
        "rel_pred = m_rel.predict(X_rel_test)\n",
        "rel_pred = np.clip(rel_pred, -REL_CLIP, REL_CLIP)\n",
        "\n",
        "log_pred = m_log.predict(X_log_test, num_iteration=m_log.best_iteration)\n",
        "abs_from_log = np.expm1(log_pred)\n",
        "abs_from_log = np.clip(abs_from_log, 0, None)\n",
        "\n",
        "baseline_vals = test_proc.apply(get_baseline_value, axis=1).values.astype(float)\n",
        "pred_from_rel = baseline_vals * (1.0 + rel_pred)"
      ],
      "metadata": {
        "id": "uiKGSrG-iqPp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_pred = ENSEMBLE_W_REL * pred_from_rel + ENSEMBLE_W_LOG * abs_from_log\n",
        "\n",
        "series_median_map = train_proc.groupby('series_id')['demand'].median().to_dict()\n",
        "series_median_arr = test_proc['series_id'].map(series_median_map).fillna(train_proc['demand'].median()).values\n",
        "\n",
        "ensemble_pred = (1 - SMOOTH_ALPHA) * ensemble_pred + SMOOTH_ALPHA * series_median_arr\n",
        "\n",
        "prod_995 = train_proc.groupby('product_rk')['demand'].quantile(MAX_PRED_BY_PROD_Q).to_dict()\n",
        "prod_upper = test_proc['product_rk'].map(prod_995).fillna(train_proc['demand'].quantile(0.99)).values\n",
        "ensemble_pred = np.minimum(ensemble_pred, prod_upper)\n",
        "\n",
        "mask_no_history = test_proc['series_count'].fillna(0) < 2\n",
        "ensemble_pred[mask_no_history.values] = test_proc.loc[mask_no_history, 'prod_median'].fillna(train_proc['demand'].median()).values\n",
        "\n",
        "train_med = train_proc['demand'].median()\n",
        "pred_med = np.median(ensemble_pred) if len(ensemble_pred) > 0 else 1.0\n",
        "if pred_med > 0:\n",
        "    scale = min(1.05, max(0.95, (train_med / pred_med) ** 0.5))\n",
        "    ensemble_pred = ensemble_pred * scale\n",
        "\n",
        "ensemble_pred = np.clip(ensemble_pred, 0, None)\n",
        "ensemble_pred = np.round(ensemble_pred).astype(int)"
      ],
      "metadata": {
        "id": "3HQYizm1itq7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = test_proc[['id']].copy().reset_index(drop=True)\n",
        "submission['predicted'] = ensemble_pred\n",
        "submission = sample[['id']].merge(submission, on='id', how='left')\n",
        "submission['predicted'] = submission['predicted'].fillna(train_proc['demand'].median()).astype(int)\n",
        "submission.to_csv('submission_original.csv', index=False)"
      ],
      "metadata": {
        "id": "tCzdv-_0iv3S"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}